# -*- coding: utf-8 -*-
"""expressear_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q_l7amG7K5WTNkgJ5yU73mGKVvR3GqCC

# test 2_ExpressEar
"""

import pandas as pd
import numpy as np
import os
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt

# Load the CSV file
df = pd.read_csv(data_path)

# Display the first few rows
print(df.head())

if 'Label' not in df.columns:
    # Example: Assign label 1 for nodding activity
    df['Label'] = 1  # Modify as per your dataset

# Features and Labels
X = df.drop('Label', axis=1).values
y = df['Label'].values

# Standardize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

#reshaping for cnn
X_scaled = X_scaled.reshape((X_scaled.shape[0], X_scaled.shape[1], 1))

# labels to categorical
y = to_categorical(y)

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

model = Sequential([
    Conv1D(filters=64, kernel_size=2, padding='valid', activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),
    MaxPooling1D(pool_size=2),
    Dropout(0.5),
    Conv1D(filters=128, kernel_size=2, padding='valid', activation='relu'),
    MaxPooling1D(pool_size=2),
    Dropout(0.5),
    Flatten(),
    Dense(100, activation='relu'),
    Dropout(0.5),
    Dense(y.shape[1], activation='softmax')  # Use 'sigmoid' for binary classification
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Use 'binary_crossentropy' for binary
model.summary()

#train the model
history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)

# Evaluate on Test Data
loss, accuracy = model.evaluate(X_test, y_test)
print(f'Test Accuracy: {accuracy*100:.2f}%')

# Plot Training History
plt.figure(figsize=(12, 4))

# Accuracy Plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Loss Plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.show()

# Predict on Test Data
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)

# Display some predictions
for i in range(10):
    print(f'Predicted: {y_pred_classes[i]}, Actual: {y_true[i]}')